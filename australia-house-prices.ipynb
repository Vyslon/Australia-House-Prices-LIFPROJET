{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a8bea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:46:31.851475Z",
     "iopub.status.busy": "2022-12-09T16:46:31.850750Z",
     "iopub.status.idle": "2022-12-09T16:46:34.238243Z",
     "shell.execute_reply": "2022-12-09T16:46:34.236435Z"
    },
    "papermill": {
     "duration": 2.396133,
     "end_time": "2022-12-09T16:46:34.240490",
     "exception": false,
     "start_time": "2022-12-09T16:46:31.844357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random as rnd\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats.stats import pearsonr   \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e69a63c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:46:34.249227Z",
     "iopub.status.busy": "2022-12-09T16:46:34.248814Z",
     "iopub.status.idle": "2022-12-09T16:46:34.324467Z",
     "shell.execute_reply": "2022-12-09T16:46:34.323147Z"
    },
    "papermill": {
     "duration": 0.082576,
     "end_time": "2022-12-09T16:46:34.326689",
     "exception": false,
     "start_time": "2022-12-09T16:46:34.244113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "X = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
    "X_test_full = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33541d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:46:34.335040Z",
     "iopub.status.busy": "2022-12-09T16:46:34.334676Z",
     "iopub.status.idle": "2022-12-09T16:46:34.342158Z",
     "shell.execute_reply": "2022-12-09T16:46:34.340420Z"
    },
    "papermill": {
     "duration": 0.014642,
     "end_time": "2022-12-09T16:46:34.344875",
     "exception": false,
     "start_time": "2022-12-09T16:46:34.330233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal as mn\n",
    "\n",
    "def z_score(df, threshold=1):\n",
    "    mean, std = np.mean(df), np.std(df)\n",
    "    z_score = np.abs((df - mean) / std)\n",
    "    good = z_score < threshold\n",
    "    print(f\"Le Z-score de {threshold} correspond à une probabilité de {100 * 2 * norm.sf(3):0.2f}%\")\n",
    "    print(f\"Rejection {(~good).sum()} points\")\n",
    "    return good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb902ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:46:34.353988Z",
     "iopub.status.busy": "2022-12-09T16:46:34.352500Z",
     "iopub.status.idle": "2022-12-09T16:46:34.371859Z",
     "shell.execute_reply": "2022-12-09T16:46:34.370380Z"
    },
    "papermill": {
     "duration": 0.026055,
     "end_time": "2022-12-09T16:46:34.374262",
     "exception": false,
     "start_time": "2022-12-09T16:46:34.348207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def featureEngineering(data, test_data):\n",
    "        \n",
    "    # Removing outliers\n",
    "    filteredData = z_score(data['GrLivArea'], 3)\n",
    "    data = data[filteredData]\n",
    "    \n",
    "    data.drop(['PoolQC'], axis=1, inplace=True)\n",
    "    data.drop(['Utilities', 'Street'], axis=1, inplace=True)\n",
    "    \n",
    "    y = data.SalePrice\n",
    "    data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "    \n",
    "    XConc = pd.concat([data, test_data]).reset_index(drop=True)\n",
    "\n",
    "    objects = []\n",
    "    for i in XConc.columns:\n",
    "        if XConc[i].dtype == object:\n",
    "            objects.append(i)\n",
    "    XConc.update(XConc[objects].fillna('None'))\n",
    "\n",
    "    XConc['LotFrontage'] = XConc.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "    XConc['GarageYrBlt'] = XConc.groupby('YearBuilt')['GarageYrBlt'].transform(lambda x: x.fillna(x.median())) # -216 sur la MAE\n",
    "\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numerics = []\n",
    "    for i in XConc.columns:\n",
    "        if XConc[i].dtype in numeric_dtypes:\n",
    "            numerics.append(i)\n",
    "    data.update(XConc[numerics].fillna(0))\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numerics2 = []\n",
    "    \n",
    "    for i in XConc.columns:\n",
    "        if XConc[i].dtype in numeric_dtypes:\n",
    "            numerics2.append(i)\n",
    "    skew_features = XConc[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "    high_skew = skew_features[skew_features > 0.5]\n",
    "    skew_index = high_skew.index\n",
    "\n",
    "    for i in skew_index:\n",
    "        XConc[i] = boxcox1p(XConc[i], boxcox_normmax(XConc[i] + 1))\n",
    "        \n",
    "    for col in numerics:\n",
    "        if np.any(np.isnan(XConc[col])):\n",
    "            XConc[col] = XConc[col].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    XConc['YrBltAndRemod']=XConc['YearBuilt']+XConc['YearRemodAdd']\n",
    "    XConc['FullSF']=XConc['TotalBsmtSF'] + XConc['1stFlrSF'] + XConc['2ndFlrSF']\n",
    "\n",
    "\n",
    "    XConc['BsmtAndHouseSF'] = (XConc['BsmtFinSF1'] + XConc['BsmtFinSF2'] +  XConc['1stFlrSF'] + XConc['2ndFlrSF'])\n",
    "\n",
    "    XConc['BathroomsCount'] = (XConc['FullBath'] + (0.5 * XConc['HalfBath']) + XConc['BsmtFullBath'] + (0.5 * XConc['BsmtHalfBath']))\n",
    "\n",
    "    XConc['PorchSF'] = (XConc['OpenPorchSF'] + XConc['3SsnPorch'] + XConc['EnclosedPorch'] + XConc['ScreenPorch'] +\n",
    "                          XConc['WoodDeckSF'])\n",
    "\n",
    "    XConc['haspool'] = XConc['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    XConc['has2ndfloor'] = XConc['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    XConc['hasgarage'] = XConc['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    XConc['hasbsmt'] = XConc['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    XConc['hasfireplace'] = XConc['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    # TODO : trouver des groupby?\n",
    "\n",
    "    \n",
    "    return XConc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d620d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:46:34.381602Z",
     "iopub.status.busy": "2022-12-09T16:46:34.381296Z",
     "iopub.status.idle": "2022-12-09T16:46:34.741051Z",
     "shell.execute_reply": "2022-12-09T16:46:34.739651Z"
    },
    "papermill": {
     "duration": 0.36586,
     "end_time": "2022-12-09T16:46:34.743339",
     "exception": false,
     "start_time": "2022-12-09T16:46:34.377479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Z-score de 3 correspond à une probabilité de 0.27%\n",
      "Rejection 16 points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1117: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1117: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1117: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1117: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1117: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:7511: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = expressions.where(mask, this, that)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/stats/stats.py:4053: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n",
      "  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "my_model_2 = XGBRegressor(eta='0.001', n_estimators=1000, learning_rate=0.03, random_state=0, min_child_weight=7, max_depth=5, n_jobs=-1, subsample=0.55,\n",
    "                              colsample_bytree=0.2, reg_lambda=3.5, alpha=110000)\n",
    "\n",
    "resXConc, y = featureEngineering(X, X_test_full)\n",
    "final_features = pd.get_dummies(resXConc).reset_index(drop=True)\n",
    "\n",
    "#print(np.any(np.isnan(final_features)))\n",
    "\n",
    "X = final_features.iloc[:len(y), :]\n",
    "X_sub = final_features.iloc[len(X):, :]\n",
    "\n",
    "#my_model_2.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19dd638a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:46:34.751474Z",
     "iopub.status.busy": "2022-12-09T16:46:34.751162Z",
     "iopub.status.idle": "2022-12-09T16:47:26.863113Z",
     "shell.execute_reply": "2022-12-09T16:47:26.861688Z"
    },
    "papermill": {
     "duration": 52.118916,
     "end_time": "2022-12-09T16:47:26.865666",
     "exception": false,
     "start_time": "2022-12-09T16:46:34.746750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model1 rmse = 20547.424285851932\n",
      ": model2 rmse = 23047.835911295777\n",
      ": model3 rmse = 22325.8505377069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model4 rmse = 18359.164613009365\n",
      ": average all models rmse = 21070.068836966\n",
      "fold: 2\n",
      ": model1 rmse = 29213.130567364915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model2 rmse = 30244.71018904988\n",
      ": model3 rmse = 27079.055248163182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model4 rmse = 26300.91879814542\n",
      ": average all models rmse = 28209.45370068085\n",
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model1 rmse = 26855.007462655736\n",
      ": model2 rmse = 26941.116053001228\n",
      ": model3 rmse = 25176.41366868245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model4 rmse = 24763.223519891682\n",
      ": average all models rmse = 25933.940176057775\n",
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model1 rmse = 18986.836812945145\n",
      ": model2 rmse = 20510.5484104918\n",
      ": model3 rmse = 19102.490307246942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model4 rmse = 17482.62475269536\n",
      ": average all models rmse = 19020.625070844813\n",
      "fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model1 rmse = 21124.183020751472\n",
      ": model2 rmse = 23249.476299410468\n",
      ": model3 rmse = 19015.91433860506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": model4 rmse = 20218.601476478718\n",
      ": average all models rmse = 20902.04378381143\n",
      "fold: 1, rmse: 18618.048545591657\n",
      "fold: 2, rmse: 25748.420855484525\n",
      "fold: 3, rmse: 23732.715708581683\n",
      "fold: 4, rmse: 16736.186361600772\n",
      "fold: 5, rmse: 18290.436236051657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.584e+11, tolerance: 6.571e+08\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+11, tolerance: 5.831e+08\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e+11, tolerance: 6.073e+08\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.676e+11, tolerance: 6.228e+08\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+11, tolerance: 6.585e+08\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "pred1 = np.zeros(X.shape[0])\n",
    "pred2 = np.zeros(X.shape[0])\n",
    "pred3 = np.zeros(X.shape[0])\n",
    "pred4 = np.zeros(X.shape[0])\n",
    "\n",
    "test1 = np.zeros(X_sub.shape[0])\n",
    "test2 = np.zeros(X_sub.shape[0])\n",
    "test3 = np.zeros(X_sub.shape[0])\n",
    "test4 = np.zeros(X_sub.shape[0])\n",
    "\n",
    "params_lgb = {'reg_alpha': 4.973064761998367, 'reg_lambda': 0.06365096912006087,'colsample_bytree': 0.24,\n",
    "              'subsample': 0.8, 'learning_rate': 0.015, 'max_depth': 100, 'num_leaves': 43,'min_child_samples': 141,\n",
    "              'cat_smooth': 18,'metric': 'rmse', 'random_state': 48,'n_estimators': 40000}\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=48,shuffle=True)\n",
    "n=0\n",
    "\n",
    "for trn_idx, test_idx in kf.split(X, y):\n",
    "    print(f\"fold: {n+1}\")\n",
    "    X_tr,X_val = X.iloc[trn_idx],X.iloc[test_idx]\n",
    "    y_tr,y_val= y.iloc[trn_idx] , y.iloc[test_idx]\n",
    "    \n",
    "    \n",
    "    model1 = lgb.LGBMRegressor()\n",
    "    model1.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=False)\n",
    "    pred1[test_idx] = model1.predict(X_val)\n",
    "    test1 += model1.predict(X_sub)/kf.n_splits\n",
    "    rmse1 = mean_squared_error(y_val, model1.predict(X_val), squared=False)\n",
    "    print(\": model1 rmse = {}\".format(rmse1))\n",
    "    \n",
    "    model2 = RandomForestRegressor(random_state=1)\n",
    "    model2.fit(X_tr,y_tr)\n",
    "    pred2[test_idx] = model2.predict(X_val)\n",
    "    test2 += model2.predict(X_sub)/kf.n_splits\n",
    "    rmse2 = mean_squared_error(y_val, model2.predict(X_val), squared=False)\n",
    "    print(\": model2 rmse = {}\".format(rmse2))    \n",
    "\n",
    "    model3 = Ridge()\n",
    "    model3.fit(X_tr,y_tr)\n",
    "    pred3[test_idx] = model3.predict(X_val)\n",
    "    test3 += model3.predict(X_sub)/kf.n_splits\n",
    "    rmse3 = mean_squared_error(y_val, model3.predict(X_val), squared=False)\n",
    "    print(\": model3 rmse = {}\".format(rmse3))\n",
    "    \n",
    "    model4 = XGBRegressor(n_estimators=800, learning_rate=0.03, random_state=0, min_child_weight=7, max_depth=5, n_jobs=-1, subsample=0.5)\n",
    "    model4.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=False)\n",
    "    pred4[test_idx] = model4.predict(X_val)\n",
    "    test4 += model4.predict(X_sub)/kf.n_splits\n",
    "    rmse4 = mean_squared_error(y_val, model4.predict(X_val), squared=False)\n",
    "    print(\": model4 rmse = {}\".format(rmse4))\n",
    "    print(\": average all models rmse = {}\".format((rmse1+rmse2+rmse3+rmse4)/4))\n",
    "\n",
    "    n+=1\n",
    "    \n",
    "stacked_predictions = np.column_stack((pred1,pred2,pred3, pred4))\n",
    "stacked_test_predictions = np.column_stack((test1,test2,test3, test4))\n",
    "\n",
    "l1_train = pd.DataFrame(data={\n",
    "    \"lgbm\": pred1.tolist(),\n",
    "    \"RandomForestRegressor\": pred2.tolist(),\n",
    "    \"LinearRegression\": pred3.tolist(),\n",
    "    \"xgb\": pred4.tolist(),\n",
    "    \"target\": y\n",
    "    })\n",
    "l1_test = pd.DataFrame(data={\n",
    "    \"lgbm\": test1.tolist(),\n",
    "    \"RandomForestRegressor\": test2.tolist(),\n",
    "    \"LinearRegression\": test3.tolist(),\n",
    "    \"xgb\": test4.tolist()\n",
    "    })\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=48,shuffle=True)\n",
    "final_prediction = np.zeros(X_sub.shape[0])\n",
    "rmse=[]  # list contains rmse for each fold\n",
    "n=0\n",
    "for trn_idx, test_idx in kf.split(stacked_predictions, y):\n",
    "    X_tr,X_val=stacked_predictions[trn_idx],stacked_predictions[test_idx]\n",
    "    y_tr,y_val=y.iloc[trn_idx],y.iloc[test_idx]\n",
    "    \n",
    "    meta_model = Lasso(alpha =0.00001)\n",
    "    \n",
    "    meta_model.fit(X_tr,y_tr)\n",
    "    \n",
    "    final_prediction +=meta_model.predict(stacked_test_predictions)/kf.n_splits\n",
    "    rmse.append(mean_squared_error(y_val, meta_model.predict(X_val), squared=False))\n",
    "    print(f\"fold: {n+1}, rmse: {rmse[n]}\")\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7626ebf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:47:26.877670Z",
     "iopub.status.busy": "2022-12-09T16:47:26.877320Z",
     "iopub.status.idle": "2022-12-09T16:47:26.881764Z",
     "shell.execute_reply": "2022-12-09T16:47:26.880440Z"
    },
    "papermill": {
     "duration": 0.01341,
     "end_time": "2022-12-09T16:47:26.884539",
     "exception": false,
     "start_time": "2022-12-09T16:47:26.871129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scores = -1 * cross_val_score(my_model_2, X, y,\n",
    "#                              cv=5,\n",
    "#                              scoring='neg_mean_absolute_error')\n",
    "#print(\"Average MAE score (across experiments):\")\n",
    "#print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32cefedd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:47:26.895689Z",
     "iopub.status.busy": "2022-12-09T16:47:26.895367Z",
     "iopub.status.idle": "2022-12-09T16:47:39.364829Z",
     "shell.execute_reply": "2022-12-09T16:47:39.363659Z"
    },
    "papermill": {
     "duration": 12.477998,
     "end_time": "2022-12-09T16:47:39.367452",
     "exception": false,
     "start_time": "2022-12-09T16:47:26.889454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.2,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='', lambda=3.5,\n",
      "             learning_rate=0.03, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=7,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=1000,\n",
      "             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "             reg_alpha=0, ...)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9100205001205651\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'colsample_bytree': 0.2, 'lambda': 3.5, 'learning_rate': 0.03, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "params = {'colsample_bytree': [0.2],\n",
    "          'lambda': [3.5],\n",
    "          'learning_rate': [0.03],\n",
    "          'n_estimators' : [1000]\n",
    "           }\n",
    "\n",
    "xgb1 = XGBRegressor(n_estimators=800, learning_rate=0.03, random_state=0, min_child_weight=7, max_depth=5, n_jobs=-1, subsample=0.5)\n",
    "\n",
    "\n",
    "\n",
    "gcv = GridSearchCV(xgb1, param_grid=params, cv=2, n_jobs=-1)\n",
    "gcv.fit(X, y)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",gcv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",gcv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",gcv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c8c9244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T16:47:39.379698Z",
     "iopub.status.busy": "2022-12-09T16:47:39.379120Z",
     "iopub.status.idle": "2022-12-09T16:47:39.391204Z",
     "shell.execute_reply": "2022-12-09T16:47:39.390143Z"
    },
    "papermill": {
     "duration": 0.02152,
     "end_time": "2022-12-09T16:47:39.393944",
     "exception": false,
     "start_time": "2022-12-09T16:47:39.372424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Submit\n",
    "#predsSub = my_model_2.predict(X_sub)\n",
    "output = pd.DataFrame({'Id': X_sub.Id,\n",
    "                       'SalePrice': final_prediction})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1ad62",
   "metadata": {
    "papermill": {
     "duration": 0.004953,
     "end_time": "2022-12-09T16:47:39.404392",
     "exception": false,
     "start_time": "2022-12-09T16:47:39.399439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 77.545654,
   "end_time": "2022-12-09T16:47:42.030401",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-09T16:46:24.484747",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
